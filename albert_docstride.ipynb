{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c0b5b7-7707-4f49-bbce-5e714d74a0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pillai4/.local/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Running Epoch : 100%|██████████| 2320/2320 [18:39<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0\n",
      "Accuracy: 0.6097675492794349\n",
      "Loss: 1.175617681238158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:30<00:00, 75.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.46127039556103383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 2320/2320 [18:39<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1\n",
      "Accuracy: 0.7243322814333027\n",
      "Loss: 0.6985109719736823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:30<00:00, 75.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.47690101488505504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 2320/2320 [18:38<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2\n",
      "Accuracy: 0.7862588516083256\n",
      "Loss: 0.4803328792179196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:30<00:00, 75.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.47453938328583806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 2320/2320 [18:38<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3\n",
      "Accuracy: 0.8263123460627836\n",
      "Loss: 0.35151678011752663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [03:29<00:00, 75.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4751400423991494\n",
      "WER (after adding doc stride)-  [1.0561560833737276, 0.850678623364033, 0.8756422685409597, 0.7927047988366457]\n",
      "F1 Scores (per epoch)-  [0.46127039556103383, 0.47690101488505504, 0.47453938328583806, 0.4751400423991494]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AlbertModel, AlbertTokenizerFast, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from evaluate import load\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Load data\n",
    "def get_data(path): \n",
    "    with open(path, 'rb') as f:\n",
    "        raw_data = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_q = 0\n",
    "\n",
    "    for group in raw_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                num_q += 1\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "    return num_q, contexts, questions, answers\n",
    "\n",
    "num_q, train_contexts, train_questions, train_answers = get_data('Spoken-SQuAD-master/spoken_train-v1.1.json')\n",
    "num_q_valid, valid_contexts, valid_questions, valid_answers = get_data('Spoken-SQuAD-master/spoken_test-v1.1.json')\n",
    "\n",
    "def add_answer_end(answers):\n",
    "    for answer in answers:\n",
    "        answer['text'] = answer['text'].lower()\n",
    "        answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n",
    "\n",
    "add_answer_end(train_answers)\n",
    "add_answer_end(valid_answers)\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"albert-base-v2\"\n",
    "doc_stride = 128\n",
    "\n",
    "tokenizerFast = AlbertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "train_encodings_fast = tokenizerFast(train_questions, train_contexts, max_length=MAX_LENGTH, truncation=True, stride=doc_stride, padding=True)\n",
    "valid_encodings_fast = tokenizerFast(valid_questions, valid_contexts, max_length=MAX_LENGTH, truncation=True, stride=doc_stride, padding=True)\n",
    "\n",
    "def ret_Answer_start_and_end(idx, answers, encodings):\n",
    "    ret_start = 0\n",
    "    ret_end = 0\n",
    "    answer_encoding_fast = tokenizerFast(answers[idx]['text'], max_length=MAX_LENGTH, truncation=True, padding=True)\n",
    "    \n",
    "    # Track if a match was found\n",
    "    match_found = False\n",
    "    \n",
    "    for a in range(len(encodings['input_ids'][idx]) - len(answer_encoding_fast['input_ids'])):\n",
    "        match = True\n",
    "        for i in range(1, len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if answer_encoding_fast['input_ids'][i] != encodings['input_ids'][idx][a + i]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            ret_start = a + 1\n",
    "            ret_end = a + len(answer_encoding_fast['input_ids']) - 1  # Corrected end position\n",
    "            match_found = True\n",
    "            break\n",
    "            \n",
    "    if not match_found:\n",
    "        # # If no match was found, return default values or handle as needed\n",
    "        ret_start = 0\n",
    "        ret_end = 0\n",
    "    \n",
    "    return ret_start, ret_end\n",
    "\n",
    "# Update train encodings with start and end positions\n",
    "train_start_positions = []\n",
    "train_end_positions = []\n",
    "for h in range(len(train_encodings_fast['input_ids'])):\n",
    "    s, e = ret_Answer_start_and_end(h, train_answers, train_encodings_fast)\n",
    "    train_start_positions.append(s)\n",
    "    train_end_positions.append(e)\n",
    "\n",
    "train_encodings_fast.update({'start_positions': train_start_positions, 'end_positions': train_end_positions})\n",
    "\n",
    "# Update valid encodings with start and end positions\n",
    "valid_start_positions = []\n",
    "valid_end_positions = []\n",
    "for h in range(len(valid_encodings_fast['input_ids'])):\n",
    "    s, e = ret_Answer_start_and_end(h, valid_answers, valid_encodings_fast)\n",
    "    valid_start_positions.append(s)\n",
    "    valid_end_positions.append(e)\n",
    "\n",
    "valid_encodings_fast.update({'start_positions': valid_start_positions, 'end_positions': valid_end_positions})\n",
    "\n",
    "class InputDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n",
    "            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "train_dataset = InputDataset(train_encodings_fast)\n",
    "valid_dataset = InputDataset(valid_encodings_fast)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "# Load ALBERT model\n",
    "albert_model = AlbertModel.from_pretrained(MODEL_PATH)\n",
    "\n",
    "class QAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QAModel, self).__init__()\n",
    "        self.albert = albert_model\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.l1 = nn.Linear(768 * 2, 768 * 2)\n",
    "        self.l2 = nn.Linear(768 * 2, 2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            self.drop_out,\n",
    "            self.l1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.l2 \n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        model_output = self.albert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = model_output[2]\n",
    "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)\n",
    "        logits = self.linear_relu_stack(out)\n",
    "        \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits\n",
    "\n",
    "model = QAModel()\n",
    "\n",
    "def focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    probs_start = smax(start_logits)\n",
    "    inv_probs_start = 1 - probs_start\n",
    "    probs_end = smax(end_logits)\n",
    "    inv_probs_end = 1 - probs_end\n",
    "    \n",
    "    lsmax = nn.LogSoftmax(dim=1)\n",
    "    log_probs_start = lsmax(start_logits)\n",
    "    log_probs_end = lsmax(end_logits)\n",
    "    \n",
    "    nll = nn.NLLLoss()\n",
    "    \n",
    "    fl_start = nll(torch.pow(inv_probs_start, gamma) * log_probs_start, start_positions)\n",
    "    fl_end = nll(torch.pow(inv_probs_end, gamma) * log_probs_end, end_positions)\n",
    "    \n",
    "    return ((fl_start + fl_end) / 2)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "total_acc = []\n",
    "total_loss = []\n",
    "\n",
    "def train_epoch(model, dataloader, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    for batch in tqdm(dataloader, desc='Running Epoch '):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        out_start, out_end = model(input_ids=input_ids, \n",
    "                                   attention_mask=attention_mask,\n",
    "                                   token_type_ids=token_type_ids)\n",
    "\n",
    "        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions, 1)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        start_pred = torch.argmax(out_start, dim=1)\n",
    "        end_pred = torch.argmax(out_end, dim=1)\n",
    "            \n",
    "        acc.append(((start_pred == start_positions).sum() / len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_positions).sum() / len(end_pred)).item())\n",
    "\n",
    "    ret_acc = sum(acc) / len(acc)\n",
    "    ret_loss = sum(losses) / len(losses)\n",
    "    return (ret_acc, ret_loss)\n",
    "\n",
    "def eval_model(model, dataloader):\n",
    "    model.eval()\n",
    "    answer_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Running Evaluation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_true = batch['start_positions'].to(device)\n",
    "            end_true = batch['end_positions'].to(device)\n",
    "            \n",
    "            out_start, out_end = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "            start_pred = torch.argmax(out_start)\n",
    "            end_pred = torch.argmax(out_end)\n",
    "            answer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_pred:end_pred]))\n",
    "            tanswer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_true[0]:end_true[0]]))\n",
    "            answer_list.append([answer, tanswer])\n",
    "\n",
    "    return answer_list\n",
    "\n",
    "wer = load(\"wer\")\n",
    "EPOCHS = 4\n",
    "model.to(device)\n",
    "wer_list = []\n",
    "f1_scores = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss = train_epoch(model, train_data_loader, epoch + 1)\n",
    "    print('Epoch - {}'.format(epoch))\n",
    "    print(f\"Accuracy: {train_acc}\")\n",
    "    print(f\"Loss: {train_loss}\")\n",
    "    answer_list = eval_model(model, valid_data_loader)\n",
    "    pred_answers = []\n",
    "    true_answers = []\n",
    "    for i in range(len(answer_list)):\n",
    "        if len(answer_list[i][0]) == 0:\n",
    "            answer_list[i][0] = \"$\"\n",
    "        if len(answer_list[i][1]) == 0:\n",
    "            answer_list[i][1] = \"$\"\n",
    "        pred_answers.append(answer_list[i][0])\n",
    "        true_answers.append(answer_list[i][1])\n",
    "    \n",
    "    wer_score = wer.compute(predictions=pred_answers, references=true_answers)\n",
    "    wer_list.append(wer_score)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_answers, pred_answers, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "print('WER (after adding doc stride)- ', wer_list)\n",
    "print('F1 Scores (per epoch)- ', f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e2649-4791-4789-bacc-2af2858b2e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
